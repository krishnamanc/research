{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 347\u001b[0m\n\u001b[0;32m    345\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, (algorithm, X) \u001b[38;5;129;01min\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 347\u001b[0m     accuracy, best_fitness, mean_fitness \u001b[38;5;241m=\u001b[39m \u001b[43mrun_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy,\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Fitness\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_fitness,\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Fitness\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_fitness\n\u001b[0;32m    352\u001b[0m     }\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Calculate Friedman ranks\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 293\u001b[0m, in \u001b[0;36mrun_algorithm\u001b[1;34m(algorithm, X, y, n_splits)\u001b[0m\n\u001b[0;32m    290\u001b[0m     mean_fitness \u001b[38;5;241m=\u001b[39m accuracy\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# For optimization algorithms\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     best_solution, best_fitness, mean_fitness \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m X_test[:, best_solution\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)]\n\u001b[0;32m    295\u001b[0m     model \u001b[38;5;241m=\u001b[39m BMFK()\n",
      "Cell \u001b[1;32mIn[1], line 76\u001b[0m, in \u001b[0;36mGA.optimize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     73\u001b[0m fitness_history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_generations):\n\u001b[1;32m---> 76\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     fitness_history\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(fitness))\n\u001b[0;32m     79\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(fitness)\n",
      "Cell \u001b[1;32mIn[1], line 100\u001b[0m, in \u001b[0;36mGA.calculate_fitness\u001b[1;34m(self, population, X, y)\u001b[0m\n\u001b[0;32m     98\u001b[0m         model \u001b[38;5;241m=\u001b[39m BMFK()\n\u001b[0;32m     99\u001b[0m         model\u001b[38;5;241m.\u001b[39mfit(selected_features, y)\n\u001b[1;32m--> 100\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m         fitness\u001b[38;5;241m.\u001b[39mappend(accuracy_score(y, y_pred))\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(fitness)\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mBMFK.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[1;32m---> 40\u001b[0m     distances, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[indices[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m     42\u001b[0m     neighbor_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[indices[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\manch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_base.py:849\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    842\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    845\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[0;32m    846\u001b[0m     )\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[1;32m--> 849\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[0;32m    861\u001b[0m ):\n\u001b[0;32m    862\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[0;32m    863\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[0;32m    864\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\manch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:278\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    291\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    292\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    299\u001b[0m     )\n",
      "File \u001b[1;32msklearn\\\\metrics\\\\_pairwise_distances_reduction\\\\_argkmin.pyx:59\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\manch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\threadpoolctl.py:592\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[0;32m    595\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import friedmanchisquare\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# BMFK class\n",
    "class BMFK:\n",
    "    def __init__(self, n_neighbors=5, m=2, p=2, q=2):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.m = m\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors, metric='minkowski', p=2)\n",
    "        self.nn.fit(X)\n",
    "\n",
    "    def bonferroni_mean(self, values):\n",
    "        n = len(values)\n",
    "        if n <= 1:\n",
    "            return np.mean(values)\n",
    "        sum_pq = 0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    sum_pq += values[i]**self.p * values[j]**self.q\n",
    "        return (sum_pq / (n * (n-1)))**(1 / (self.p + self.q))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            neighbors = self.X[indices[0]]\n",
    "            neighbor_labels = self.y[indices[0]]\n",
    "            \n",
    "            memberships = 1 / (distances[0] ** (2 / (self.m - 1)) + 1e-8)\n",
    "            memberships /= np.sum(memberships)\n",
    "            \n",
    "            class_memberships = {}\n",
    "            for c in self.classes:\n",
    "                class_indices = neighbor_labels == c\n",
    "                if np.any(class_indices):\n",
    "                    class_memberships[c] = self.bonferroni_mean(memberships[class_indices])\n",
    "                else:\n",
    "                    class_memberships[c] = 0\n",
    "            \n",
    "            predictions.append(max(class_memberships, key=class_memberships.get))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "# Heuristic Algorithms\n",
    "class GA:\n",
    "    def __init__(self, pop_size=50, n_generations=100, crossover_rate=0.8, mutation_rate=0.1):\n",
    "        self.pop_size = pop_size\n",
    "        self.n_generations = n_generations\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        population = np.random.randint(2, size=(self.pop_size, n_features))\n",
    "        \n",
    "        best_fitness = 0\n",
    "        best_solution = None\n",
    "        fitness_history = []\n",
    "\n",
    "        for _ in range(self.n_generations):\n",
    "            fitness = self.calculate_fitness(population, X, y)\n",
    "            fitness_history.append(np.mean(fitness))\n",
    "            \n",
    "            best_idx = np.argmax(fitness)\n",
    "            if fitness[best_idx] > best_fitness:\n",
    "                best_fitness = fitness[best_idx]\n",
    "                best_solution = population[best_idx]\n",
    "\n",
    "            parents = self.selection(population, fitness)\n",
    "            offspring = self.crossover(parents)\n",
    "            offspring = self.mutation(offspring)\n",
    "            population = offspring\n",
    "\n",
    "        return best_solution, best_fitness, np.mean(fitness_history)\n",
    "\n",
    "    def calculate_fitness(self, population, X, y):\n",
    "        fitness = []\n",
    "        for individual in population:\n",
    "            selected_features = X[:, individual.astype(bool)]\n",
    "            if selected_features.shape[1] == 0:\n",
    "                fitness.append(0)\n",
    "            else:\n",
    "                model = BMFK()\n",
    "                model.fit(selected_features, y)\n",
    "                y_pred = model.predict(selected_features)\n",
    "                fitness.append(accuracy_score(y, y_pred))\n",
    "        return np.array(fitness)\n",
    "\n",
    "    def selection(self, population, fitness):\n",
    "        return population[np.argsort(fitness)[-self.pop_size//2:]]\n",
    "\n",
    "    def crossover(self, parents):\n",
    "        offspring = []\n",
    "        np.random.shuffle(parents)  # Shuffle parents to ensure random pairing\n",
    "        for i in range(0, len(parents) - 1, 2):  # Ensure we always have pairs\n",
    "            if np.random.rand() < self.crossover_rate:\n",
    "                crossover_point = np.random.randint(1, len(parents[i]))\n",
    "                offspring.append(np.concatenate((parents[i][:crossover_point], parents[i+1][crossover_point:])))\n",
    "                offspring.append(np.concatenate((parents[i+1][:crossover_point], parents[i][crossover_point:])))\n",
    "            else:\n",
    "                offspring.extend([parents[i], parents[i+1]])\n",
    "        \n",
    "        # If there's an odd number of parents, add the last one without crossover\n",
    "        if len(parents) % 2 != 0:\n",
    "            offspring.append(parents[-1])\n",
    "        \n",
    "        return np.array(offspring)\n",
    "\n",
    "    def mutation(self, offspring):\n",
    "        for i in range(len(offspring)):\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                mutation_point = np.random.randint(0, len(offspring[i]))\n",
    "                offspring[i][mutation_point] = 1 - offspring[i][mutation_point]\n",
    "        return offspring\n",
    "\n",
    "class PSO:\n",
    "    def __init__(self, n_particles=30, n_iterations=100, w=0.7, c1=1.5, c2=1.5):\n",
    "        self.n_particles = n_particles\n",
    "        self.n_iterations = n_iterations\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        particles = np.random.rand(self.n_particles, n_features)\n",
    "        velocities = np.zeros_like(particles)\n",
    "        personal_best = particles.copy()\n",
    "        personal_best_fitness = np.zeros(self.n_particles)\n",
    "        global_best = None\n",
    "        global_best_fitness = -np.inf\n",
    "        fitness_history = []\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            fitness = self.calculate_fitness(particles, X, y)\n",
    "            fitness_history.append(np.mean(fitness))\n",
    "\n",
    "            # Update personal and global best\n",
    "            improved = fitness > personal_best_fitness\n",
    "            personal_best[improved] = particles[improved]\n",
    "            personal_best_fitness[improved] = fitness[improved]\n",
    "\n",
    "            if np.max(fitness) > global_best_fitness:\n",
    "                global_best = particles[np.argmax(fitness)]\n",
    "                global_best_fitness = np.max(fitness)\n",
    "\n",
    "            # Update velocities and positions\n",
    "            r1, r2 = np.random.rand(2, self.n_particles, n_features)\n",
    "            velocities = (self.w * velocities +\n",
    "                          self.c1 * r1 * (personal_best - particles) +\n",
    "                          self.c2 * r2 * (global_best - particles))\n",
    "            particles = np.clip(particles + velocities, 0, 1)\n",
    "\n",
    "        return (global_best > 0.5).astype(int), global_best_fitness, np.mean(fitness_history)\n",
    "\n",
    "    def calculate_fitness(self, particles, X, y):\n",
    "        fitness = []\n",
    "        for particle in particles:\n",
    "            selected_features = X[:, (particle > 0.5).astype(bool)]\n",
    "            if selected_features.shape[1] == 0:\n",
    "                fitness.append(0)\n",
    "            else:\n",
    "                model = BMFK()\n",
    "                model.fit(selected_features, y)\n",
    "                y_pred = model.predict(selected_features)\n",
    "                fitness.append(accuracy_score(y, y_pred))\n",
    "        return np.array(fitness)\n",
    "\n",
    "class GWO:\n",
    "    def __init__(self, n_wolves=30, n_iterations=100):\n",
    "        self.n_wolves = n_wolves\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        wolves = np.random.rand(self.n_wolves, n_features)\n",
    "        alpha, beta, delta = None, None, None\n",
    "        alpha_score, beta_score, delta_score = -np.inf, -np.inf, -np.inf\n",
    "        fitness_history = []\n",
    "\n",
    "        for t in range(self.n_iterations):\n",
    "            fitness = self.calculate_fitness(wolves, X, y)\n",
    "            fitness_history.append(np.mean(fitness))\n",
    "\n",
    "            # Update alpha, beta, and delta\n",
    "            for i in range(self.n_wolves):\n",
    "                if fitness[i] > alpha_score:\n",
    "                    alpha_score = fitness[i]\n",
    "                    alpha = wolves[i].copy()\n",
    "                elif fitness[i] > beta_score:\n",
    "                    beta_score = fitness[i]\n",
    "                    beta = wolves[i].copy()\n",
    "                elif fitness[i] > delta_score:\n",
    "                    delta_score = fitness[i]\n",
    "                    delta = wolves[i].copy()\n",
    "\n",
    "            a = 2 - t * (2 / self.n_iterations)\n",
    "            for i in range(self.n_wolves):\n",
    "                for j in range(n_features):\n",
    "                    r1, r2 = np.random.rand(2)\n",
    "                    A1, C1 = 2 * a * r1 - a, 2 * r2\n",
    "                    D_alpha = abs(C1 * alpha[j] - wolves[i, j])\n",
    "                    X1 = alpha[j] - A1 * D_alpha\n",
    "\n",
    "                    r1, r2 = np.random.rand(2)\n",
    "                    A2, C2 = 2 * a * r1 - a, 2 * r2\n",
    "                    D_beta = abs(C2 * beta[j] - wolves[i, j])\n",
    "                    X2 = beta[j] - A2 * D_beta\n",
    "\n",
    "                    r1, r2 = np.random.rand(2)\n",
    "                    A3, C3 = 2 * a * r1 - a, 2 * r2\n",
    "                    D_delta = abs(C3 * delta[j] - wolves[i, j])\n",
    "                    X3 = delta[j] - A3 * D_delta\n",
    "\n",
    "                    wolves[i, j] = (X1 + X2 + X3) / 3\n",
    "\n",
    "            wolves = np.clip(wolves, 0, 1)\n",
    "\n",
    "        return (alpha > 0.5).astype(int), alpha_score, np.mean(fitness_history)\n",
    "\n",
    "    def calculate_fitness(self, wolves, X, y):\n",
    "        fitness = []\n",
    "        for wolf in wolves:\n",
    "            selected_features = X[:, (wolf > 0.5).astype(bool)]\n",
    "            if selected_features.shape[1] == 0:\n",
    "                fitness.append(0)\n",
    "            else:\n",
    "                model = BMFK()\n",
    "                model.fit(selected_features, y)\n",
    "                y_pred = model.predict(selected_features)\n",
    "                fitness.append(accuracy_score(y, y_pred))\n",
    "        return np.array(fitness)\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Full_new\")\n",
    "    df = df.drop(columns=['Sl. No', 'Patient File No.', 'Unnamed: 44'])\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    categorical_columns = ['Blood Group', 'Cycle(R/I)', 'Pregnant(Y/N)', \n",
    "                          'Weight gain(Y/N)', 'hair growth(Y/N)', \n",
    "                          'Skin darkening (Y/N)', 'Hair loss(Y/N)', \n",
    "                          'Pimples(Y/N)', 'Fast food (Y/N)', \n",
    "                          'Reg.Exercise(Y/N)']\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    X = df.drop(columns=['PCOS (Y/N)'])\n",
    "    y = df['PCOS (Y/N)'].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y, X.columns\n",
    "\n",
    "def run_algorithm(algorithm, X, y, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    best_fitnesses = []\n",
    "    mean_fitnesses = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        if isinstance(algorithm, BMFK):\n",
    "            # For BMFK, we don't need feature selection\n",
    "            model = algorithm\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            best_fitness = accuracy\n",
    "            mean_fitness = accuracy\n",
    "        else:\n",
    "            # For optimization algorithms\n",
    "            best_solution, best_fitness, mean_fitness = algorithm.optimize(X_train, y_train)\n",
    "            selected_features = X_test[:, best_solution.astype(bool)]\n",
    "            model = BMFK()\n",
    "            model.fit(X_train[:, best_solution.astype(bool)], y_train)\n",
    "            y_pred = model.predict(selected_features)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        best_fitnesses.append(best_fitness)\n",
    "        mean_fitnesses.append(mean_fitness)\n",
    "    \n",
    "    return np.mean(accuracies), np.mean(best_fitnesses), np.mean(mean_fitnesses)\n",
    "\n",
    "def calculate_friedman_ranks(cv_accuracies):\n",
    "    methods = list(cv_accuracies.keys())\n",
    "    n_methods = len(methods)\n",
    "    n_folds = len(cv_accuracies[methods[0]])\n",
    "    \n",
    "    accuracy_matrix = np.zeros((n_folds, n_methods))\n",
    "    for i, method in enumerate(methods):\n",
    "        accuracy_matrix[:, i] = cv_accuracies[method]\n",
    "    \n",
    "    rank_matrix = n_methods + 1 - pd.DataFrame(accuracy_matrix).rank(axis=1)\n",
    "    mean_ranks = rank_matrix.mean(axis=0).values\n",
    "    \n",
    "    return mean_ranks\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # File path\n",
    "    file_path = \"PCOS_data_without_infertility.xlsx\"\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X_scaled, y, feature_names = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # Define the proposed feature set\n",
    "    proposed_selected_features = ['Follicle No. (L)', 'hair growth(Y/N)', 'Follicle No. (R)', \n",
    "                                 'Cycle(R/I)', 'Fast food (Y/N)', 'Skin darkening (Y/N)', \n",
    "                                 'Cycle length(days)', 'FSH/LH']\n",
    "    \n",
    "    # Prepare the proposed feature set\n",
    "    X_proposed = X_scaled[:, [list(feature_names).index(feature) for feature in proposed_selected_features]]\n",
    "    \n",
    "    # Define algorithms\n",
    "    algorithms = {\n",
    "        \"Ensemble filter+BEEO(RL)+BMFK(proposed)\": (BMFK(), X_proposed),\n",
    "        \"GA-BMFK\": (GA(), X_scaled),\n",
    "        \"PSO-BMFK\": (PSO(), X_scaled),\n",
    "        \"GWO-BMFK\": (GWO(), X_scaled)\n",
    "    }\n",
    "    \n",
    "    # Run algorithms and collect results\n",
    "    results = {}\n",
    "    for name, (algorithm, X) in algorithms.items():\n",
    "        accuracy, best_fitness, mean_fitness = run_algorithm(algorithm, X, y)\n",
    "        results[name] = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Best Fitness\": best_fitness,\n",
    "            \"Mean Fitness\": mean_fitness\n",
    "        }\n",
    "    \n",
    "    # Calculate Friedman ranks\n",
    "    accuracies = {name: [results[name][\"Accuracy\"]] for name in algorithms.keys()}\n",
    "    friedman_ranks = calculate_friedman_ranks(accuracies)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Methods\": list(algorithms.keys()),\n",
    "        \"Best Fitness\": [results[name][\"Best Fitness\"] for name in algorithms.keys()],\n",
    "        \"Mean Fitness\": [results[name][\"Mean Fitness\"] for name in algorithms.keys()],\n",
    "        \"Accuracy\": [results[name][\"Accuracy\"] for name in algorithms.keys()],\n",
    "        \"Friedman mean rank\": friedman_ranks\n",
    "    })\n",
    "\n",
    "    # Sort by Accuracy\n",
    "    results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "    # Format and display results\n",
    "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "    print(\"\\nResults Table:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    # Perform Friedman test\n",
    "    accuracies_array = np.array([results[name][\"Accuracy\"] for name in algorithms.keys()])\n",
    "    statistic, p_value = friedmanchisquare(*[accuracies_array])\n",
    "    print(f\"\\nFriedman test statistic: {statistic:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df.to_csv(\"algorithm_comparison_results.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'algorithm_comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
