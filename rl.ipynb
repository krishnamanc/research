{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SARSA parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.95  # Discount factor\n",
    "epsilon = 0.1  # Exploration rate (we will decay this over time for more exploitation)\n",
    "\n",
    "# Define BEO parameters\n",
    "population_size = 50  # Number of individuals in the population\n",
    "n_iterations = 100  # Number of optimization iterations\n",
    "penalty_weight = 0.15  # Penalty weight for selecting too many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"/kaggle/input/pcos-ml/PCOS_data_without_infertility.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"Full_new\")\n",
    "\n",
    "# Data Preprocessing\n",
    "df = df.drop(columns=['Sl. No', 'Patient File No.', 'Unnamed: 44'])\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['Blood Group', 'Cycle(R/I)', 'Pregnant(Y/N)', \n",
    "                       'Weight gain(Y/N)', 'hair growth(Y/N)', \n",
    "                       'Skin darkening (Y/N)', 'Hair loss(Y/N)', \n",
    "                       'Pimples(Y/N)', 'Fast food (Y/N)', \n",
    "                       'Reg.Exercise(Y/N)']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=['PCOS (Y/N)'])\n",
    "y = df['PCOS (Y/N)']\n",
    "\n",
    "# Assuming these are the selected features from ensemble\n",
    "selected_features = ['Follicle No. (L)', 'hair growth(Y/N)', 'Follicle No. (R)', 'Cycle(R/I)', 'Fast food (Y/N)', \n",
    "                      'AMH(ng/mL)', 'Skin darkening (Y/N)', 'Weight gain(Y/N)', 'Pimples(Y/N)', 'Cycle length(days)', \n",
    "                      'Hip(inch)', 'Weight (Kg)', 'FSH/LH', 'FSH(mIU/mL)']\n",
    "n_features = len(selected_features)\n",
    "n_actions = n_features  # One action per feature (either include or exclude)\n",
    "\n",
    "# Initialize population (binary representation of feature subsets)\n",
    "population = np.random.randint(2, size=(population_size, n_features))\n",
    "\n",
    "# SARSA Q-table initialization\n",
    "Q = np.zeros((population_size, n_actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_solution(solution, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluate the accuracy of a solution (feature subset) and penalize for too many features.\"\"\"\n",
    "    # Use only the selected features from the solution\n",
    "    selected_columns = [selected_features[i] for i in range(len(solution)) if solution[i] == 1]\n",
    "    if len(selected_columns) == 0:\n",
    "        return 0  # If no features selected, return zero accuracy\n",
    "    \n",
    "    # Fit a simple model (e.g., XGBoost) on the selected features\n",
    "    model = xgb.XGBClassifier(eval_metric='mlogloss')\n",
    "    model.fit(X_train[selected_columns], y_train)\n",
    "    accuracy = model.score(X_test[selected_columns], y_test)\n",
    "    \n",
    "    # Apply penalty for number of selected features (objective: fewer features, high accuracy)\n",
    "    penalty = penalty_weight * len(selected_columns)\n",
    "    \n",
    "    return accuracy - penalty  # Objective: maximize accuracy, minimize features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEO + SARSA optimization loop\n",
    "for iteration in range(n_iterations):\n",
    "    for i in range(population_size):\n",
    "        # Select an action (flip a feature on/off)\n",
    "        if random.uniform(0, 1) < epsilon:  # Exploration\n",
    "            action = np.random.randint(n_actions)\n",
    "        else:  # Exploitation (SARSA policy)\n",
    "            action = np.argmax(Q[i])\n",
    "        \n",
    "        # Apply the action (flip the feature)\n",
    "        new_population = np.copy(population)\n",
    "        new_population[i][action] = 1 - new_population[i][action]\n",
    "        \n",
    "        # Evaluate the new solution\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        reward = evaluate_solution(new_population[i], X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # SARSA: Update Q-value\n",
    "        next_action = np.argmax(Q[i])  # Choose next action (greedy)\n",
    "        next_reward = evaluate_solution(new_population[i], X_train, y_train, X_test, y_test)\n",
    "        Q[i][action] += alpha * (reward + gamma * next_reward - Q[i][action])\n",
    "        \n",
    "        # Print the current selected features for each iteration\n",
    "        selected_columns = [selected_features[idx] for idx, val in enumerate(new_population[i]) if val == 1]\n",
    "        print(f\"Iteration {iteration+1}, Individual {i+1}, Selected Features: {selected_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the final solution (best individual from the population)\n",
    "best_individual_idx = np.argmax([evaluate_solution(population[i], X_train, y_train, X_test, y_test) for i in range(population_size)])\n",
    "final_solution = population[best_individual_idx]\n",
    "\n",
    "# Final selected features after optimization\n",
    "final_selected_features = [selected_features[idx] for idx, val in enumerate(final_solution) if val == 1]\n",
    "print(f\"Final Selected Features: {final_selected_features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
